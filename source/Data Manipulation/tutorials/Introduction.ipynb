{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Manipulation and analysis\n",
    "## Introduction\n",
    "In the last chapter, we have covered applied mathematics with Python and showed how computer programming can be used to solve large and complex applied mathematics problems. The number of real life applications of this combination of math and computers is so massive that many scientist compare this technological advancement with milestones like agriculture, mechanisation, or the combustion engine.\n",
    "Since the benefits are so vast, our society has been using computers programs and algorithms for an ever growing number of applications, and they have been so successful solving problems, that they have grown in size and complexity.\n",
    "This growth also means an exponential increase in the volume of data required to run these programs. Indeed, as depicted in the famous 80s movies, applications are hungry for data!\n",
    "\n",
    "Did you know that the icon used besides the save button in numerous applications represents a physical storage format used in the 80s and early 90s?\n",
    "\n",
    "![floppy disks used in the 80s and 90s](img/floppy.png)\n",
    "\n",
    "Yes, as shown in the picture, floppy disks were exactly 5,1 inches big and had a storage capacity of 1.44MB. Back in the day, that storage capacity was enough to store relevant data in most applications, but nowadays, it looks very very small. To see how small it was, the following figure represents the storage capacity of a floppy disk compared to the storage capacity of a 32GB SD card (which is actually not that big, but still enough to hold relevant data)\n",
    "\n",
    "![1.44 MB against 32GB in linear scale](img/floppy%20vs%20SD%20drive.png)\n",
    "\n",
    "The difference is so massive that it is not possible to represent both units of storage in the same linear scale. We can represent both in logarithmic scale to see how many orders of magnitude exist between both units of storage.\n",
    "\n",
    "![1.44 MB against 32GB in logarithmic scale](img/floppy%20vs%20SD%20drive%20log%20scale.png)\n",
    "\n",
    "In the figure, we added two dots, one to represent how many times the sun is larger than earth (since, as you know, the sun is way bigger than our home planet) and another one to represent how much bigger is a human compared to an ant (since we normally see the sun from really far away, this analogy might be easier to relate to). You can see that they are in the same order of magnitude! So, in few decades, programs have switched from dealing with data the size of insects to data the size of mammals.\n",
    "\n",
    "Clearly, data manipulation and analysis has become increasingly relevant in our society, but also increasingly complex. We need efficient tools and processes to deal with data in our processes.\n",
    "\n",
    "## Data processing\n",
    "Clearly, the data that builds up the matrices and vectors used by our applications need to be collected and manipulated to provide meaningful information. This is called **data processing**. Traditionally, in literature data processing is organised into a three-phase process called Extract, Transformation, and Load (ETL).\n",
    "\n",
    "![Extract Transformation and Load](img/ETL.png)\n",
    "\n",
    "- **Extraction**: In many cases, the data we need will be stored in one or several data sources, such as websites, files, or databases. The processing of reading and collecting data from these sources is called extraction.\n",
    "- **Transformation**: Often, the data might not be in the format required by our application, and we need to apply some transformations to it to adapt it. Some examples (non exhaustive) of data processing steps in this phase are:\n",
    "    - **Validation**: Make sure that only relevant, valid data is passed to the next phase, ignoring or filtering out unuseful or malformed data entries.\n",
    "    - **Translation and Encoding**: Changing the values of source data to match the expected set of values in our application.\n",
    "    - **Sorting**: Changing the order of data entries (sorting) or divide it into different sets to facilitate later analysis.\n",
    "    - **Summarization and Aggregation**: Reduce redundant data and/or derive statistics like mean values to summarize data and speed up the extraction of meaningful information.\n",
    "    - **Joining**: Combining different sources of information.\n",
    "    - **Transposing/Pivoting**: Re-arranging tabular data, changing rows into columns or viceversa.\n",
    "- **Load**: Finally, once that all transformations have been applied, we may load the transformed data into a target file or database in a format more suitable for analysis, and later read this file and load the data into objects in memory to proceed with the representation and analysis of data. This is normally done so that the transformation part does not need to be repeated everytime we analyse data. However, as data processing becomes more fast and efficient, many applications do the transformation and analysis in the same phase.\n",
    "\n",
    "In the next notebooks we will describe Pandas, a Python library that implements objects and functions to support all these data processing.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}